services:
  api:
    build:
      context: .
      dockerfile: Dockerfile
      args:
        INSTALL_ML_DEPS: "true"
        DOWNLOAD_MODELS: "true"
    image: tryon-api
    environment:
      - TRYON_OUTPUTS_DIR=/tmp/tryon/outputs
      - TRYON_UPLOADS_DIR=/tmp/tryon/uploads
      - TRYON_MODELS_DIR=/models
      - STABLEVITON_SHAREPOINT_URL
      - SCHP_DRIVE_URL
      - INSTANTID_ANTELOPE_URL
      - HUGGINGFACE_HUB_TOKEN
      - NVIDIA_VISIBLE_DEVICES=all
    ports:
      - "8008:8008"
    volumes:
      - ./outputs:/tmp/tryon/outputs
      - ./uploads:/tmp/tryon/uploads
      - ./models:/models
    healthcheck:
      test: ["CMD", "python", "-c", "import urllib.request;print(urllib.request.urlopen('http://localhost:8008/healthz').read().decode())"]
      interval: 20s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: [gpu]
    # For Compose v2 with NVIDIA toolkit, this can also be used:
    # gpus: all

  web:
    image: node:20-alpine
    working_dir: /app
    command: sh -c "npm install && npm run dev -- --host 0.0.0.0 --port 5173"
    volumes:
      - ./sdk/web:/app
    ports:
      - "5173:5173"
    depends_on:
      - api
